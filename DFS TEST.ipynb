{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19385b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ly/7vdr23qj7yn96w59b90h_zmm0000gn/T/ipykernel_32293/2329355497.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bfd['TB'] = bfd.apply(lambda r: round(r['1B'] + 2 * r['2B'] + 3 * r['3B'] + 4 * r['HR'], 2), axis=1)\n",
      "/var/folders/ly/7vdr23qj7yn96w59b90h_zmm0000gn/T/ipykernel_32293/2329355497.py:312: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bfd['DK$'] = bfd.apply(lambda r: round(r['DraftKingsPoints'] / (r['OperatorSalary'] / 1000), 2) , axis=1)\n"
     ]
    }
   ],
   "source": [
    "### RUN python dfs_get_data.py FIRST\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import date\n",
    "import json\n",
    "from pybaseball import playerid_lookup\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import unidecode\n",
    "\n",
    "\n",
    "from dfs_functions import *\n",
    "\n",
    "today = date.today()\n",
    "d = today.strftime(\"%Y-%b-%d\")\n",
    "\n",
    "sals, players = get_batter_salaries(d)\n",
    "sals_p, players_p = get_pitcher_salaries(d)\n",
    "\n",
    "game_logs = get_current_season_game_logs_batters(d)\n",
    "game_logs_p = get_current_season_game_logs_pitchers(d)\n",
    "\n",
    "league_stats = get_league_stats(d)\n",
    "\n",
    "league_hbp = league_stats.HitByPitch.sum()\n",
    "league_hr = league_stats.HomeRuns.sum()\n",
    "league_bb = league_stats.Walks.sum()\n",
    "league_so = league_stats.Strikeouts.sum()\n",
    "league_innings = game_logs_p.InningsPitchedDecimal.sum()\n",
    "league_ER = game_logs_p.ER.sum()\n",
    "\n",
    "marcels = get_marcels_batters(d)\n",
    "marcels_p = get_marcels_pitchers(d)\n",
    "\n",
    "df = marcels[['Name', 'Reliability']]\n",
    "game_logs = game_logs.merge(df, how='left', on='Name')\n",
    "game_logs = game_logs.loc[game_logs['PlayerID'].isin(players)]\n",
    "sum_data = game_logs[['PlayerID', 'PA', 'S', 'D', 'T', 'HR', 'BB', 'HP', 'SB', 'CS', 'SO']].reset_index(drop=True).groupby(['PlayerID']).sum()\n",
    "\n",
    "reliability_dict = {}\n",
    "\n",
    "df_p = marcels_p[['Name', 'Reliability']]\n",
    "game_logs_p = game_logs_p.merge(df_p, how='left', on='Name')\n",
    "game_logs_p = game_logs_p.loc[game_logs_p['PlayerID'].isin(players_p)]\n",
    "sum_data_p = game_logs_p[['PlayerID', 'Started', 'Games', 'W', 'TotalOutsPitched', 'ER', 'BB', 'SO', 'H', 'HR', 'H-HR']].reset_index(drop=True).groupby(['PlayerID']).sum()\n",
    "\n",
    "reliability_dict_p = {}\n",
    "\n",
    "for index, row in game_logs_p.iterrows():\n",
    "    if math.isnan(row['Reliability']) == True:\n",
    "        reliability_dict_p[row['PlayerID']] = 0\n",
    "    else:\n",
    "        reliability_dict_p[row['PlayerID']] = row['Reliability']\n",
    "\n",
    "for index, row in game_logs.iterrows():\n",
    "    if math.isnan(row['Reliability']) == True:\n",
    "        reliability_dict[row['PlayerID']] = 0\n",
    "    else:\n",
    "        reliability_dict[row['PlayerID']] = row['Reliability']\n",
    "\n",
    "player_stabilization_dict = create_stabilization_dict_hitters(sum_data, reliability_dict)\n",
    "pitcher_stabilization_dict = create_stabilization_dict_pitchers(sum_data_p, reliability_dict_p)\n",
    "\n",
    "marcels_dict, marcel_players = create_per_pa_marcels_rates_hitters(game_logs, marcels)\n",
    "marcels_dict_p, marcel_pitchers = create_per_pa_marcels_rates_pitchers(game_logs_p, marcels_p)\n",
    "\n",
    "new = sals['OperatorPosition'].str.split('/', n = 1, expand = True)\n",
    "sals['EffectivePosition'] = new[0]\n",
    "\n",
    "new_p = sals_p['OperatorPosition'].str.split('/', n = 1, expand = True)\n",
    "sals_p['EffectivePosition'] = new_p[0]\n",
    "\n",
    "average_stats_by_position = get_average_stats_by_position(d, game_logs, 'hitters')\n",
    "average_stats_by_position_p = get_average_stats_by_position(d, game_logs_p, 'pitchers')\n",
    "\n",
    "blended_projections_dict = create_blended_projections_hitters(players, marcel_players, player_stabilization_dict, marcels_dict, sals, average_stats_by_position)\n",
    "blended_projections_dict_p = create_blended_projections_pitchers(players_p, marcel_pitchers, pitcher_stabilization_dict, marcels_dict_p, sum_data_p, average_stats_by_position_p)\n",
    "\n",
    "sals['pS/PA'] = sals.apply(lambda row: round(blended_projections_dict[row['PlayerID']]['S'], 3) if row['PlayerID'] in blended_projections_dict else np.NaN, axis=1)\n",
    "sals['pD/PA'] = sals.apply(lambda row: round(blended_projections_dict[row['PlayerID']]['D'], 3) if row['PlayerID'] in blended_projections_dict else np.NaN, axis=1)\n",
    "sals['pT/PA'] = sals.apply(lambda row: round(blended_projections_dict[row['PlayerID']]['T'], 3) if row['PlayerID'] in blended_projections_dict else np.NaN, axis=1)\n",
    "sals['pHR/PA'] = sals.apply(lambda row: round(blended_projections_dict[row['PlayerID']]['HR'], 3) if row['PlayerID'] in blended_projections_dict else np.NaN, axis=1)\n",
    "sals['pBB/PA'] = sals.apply(lambda row: round(blended_projections_dict[row['PlayerID']]['BB'], 3) if row['PlayerID'] in blended_projections_dict else np.NaN, axis=1)\n",
    "sals['pHP/PA'] = sals.apply(lambda row: round(blended_projections_dict[row['PlayerID']]['HP'], 3) if row['PlayerID'] in blended_projections_dict else np.NaN, axis=1)\n",
    "sals['pSB/PA'] = sals.apply(lambda row: round(blended_projections_dict[row['PlayerID']]['SB'], 3) if row['PlayerID'] in blended_projections_dict else np.NaN, axis=1)\n",
    "sals['pSO/PA'] = sals.apply(lambda row: round(blended_projections_dict[row['PlayerID']]['SO'], 3) if row['PlayerID'] in blended_projections_dict else np.NaN, axis=1)\n",
    "\n",
    "sals_p['pSO/Out'] = sals_p.apply(lambda row: round(blended_projections_dict_p[row['PlayerID']]['SO'], 3) if row['PlayerID'] in blended_projections_dict_p else np.NaN, axis=1)\n",
    "sals_p['pBB/Out'] = sals_p.apply(lambda row: round(blended_projections_dict_p[row['PlayerID']]['BB'], 3) if row['PlayerID'] in blended_projections_dict_p else np.NaN, axis=1)\n",
    "sals_p['pHR/Out'] = sals_p.apply(lambda row: round(blended_projections_dict_p[row['PlayerID']]['HR'], 3) if row['PlayerID'] in blended_projections_dict_p else np.NaN, axis=1)\n",
    "sals_p['pH-HR/Out'] = sals_p.apply(lambda row: round(blended_projections_dict_p[row['PlayerID']]['H-HR'], 3) if row['PlayerID'] in blended_projections_dict_p else np.NaN, axis=1)\n",
    "sals_p['pHBP/Out'] = sals_p.apply(lambda row: round(league_hbp / (league_innings * 3), 3), axis=1)\n",
    "\n",
    "league_ERA = (9 / league_innings) * league_ER\n",
    "FIP_constant = league_ERA - (((13 * league_hr) + (3 * (league_bb + league_hbp)) - (2 * league_so)) / league_innings)\n",
    "\n",
    "game_stats_prior = get_prior_season_game_logs(d)\n",
    "\n",
    "prior_year_ind_pitcher_dist = game_stats_prior.groupby('PlayerID').TotalOutsPitched.agg(['sum', 'mean', 'std']).fillna(0)\n",
    "prior_year_league_innings_dist = game_stats_prior.TotalOutsPitched.agg(['sum', 'mean', 'std'])\n",
    "current_year_starts = game_logs.loc[game_logs.Started == 1].reset_index(drop=True)\n",
    "current_year_ind_pitcher_dist = current_year_starts.groupby('PlayerID').TotalOutsPitched.agg(['sum', 'mean', 'std']).fillna(0)\n",
    "current_year_league_innings_dist = current_year_starts.TotalOutsPitched.agg(['sum', 'mean', 'std'])\n",
    "current_year_outs = current_year_league_innings_dist['sum']\n",
    "weighted_league_innings_dist_mean = ((current_year_league_innings_dist['mean'] * current_year_outs) + (prior_year_league_innings_dist['mean'] * 10000)) / (current_year_outs + 10000)\n",
    "weighted_league_innings_dist_std = ((current_year_league_innings_dist['std'] * current_year_outs) + (prior_year_league_innings_dist['std'] * 10000)) / (current_year_outs + 10000)\n",
    "current_year_starts_vs_team = game_logs.loc[game_logs.Started == 1].groupby('OpponentID').TotalOutsPitched.agg(['sum', 'mean', 'std']).fillna(0)\n",
    "\n",
    "sals_with_vegas_lines, starting_pitchers = get_vegas_lines(d, sals)\n",
    "sals_with_vegas_lines_p, starting_pitchers = get_vegas_lines(d, sals_p)\n",
    "\n",
    "pa_sals_with_vegas_lines = adjust_for_park_factors(sals_with_vegas_lines)\n",
    "pitcher_sals_with_vegas_lines = adjust_for_park_factors_pitchers(sals_with_vegas_lines_p)\n",
    "\n",
    "## NEED TO FIGURE THE BATTING ORDER PART OUT\n",
    "#batting_order_file = get_batting_orders_file()\n",
    "\n",
    "pa_sals_with_vegas_lines['battingorderposition'] = 2\n",
    "\n",
    "sals_with_batting_order = apply_starters_obp(pa_sals_with_vegas_lines)\n",
    "\n",
    "sals_with_batting_order['pPA'] = sals_with_batting_order.apply(lambda row: 1 if pd.isnull(row['battingorderposition']) else round(3.3 + (-0.12 * row['battingorderposition']) + (.036 * row['PlayerTeamTotal']) + (3.92 * row['startersOBP']), 2), axis=1)\n",
    "sals_with_batting_order['OBP-HR'] = sals_with_batting_order.apply(lambda row: row['pS/PA'] + row['pD/PA'] + row['pT/PA'] + row['pBB/PA'] + row['pHP/PA'], axis=1)\n",
    "sals_with_batting_order['pAB/PA'] = sals_with_batting_order.apply(lambda row: 1 - row['pBB/PA'] - row['pHP/PA'], axis=1)\n",
    "\n",
    "#lead_hitters_obp_dict = find_lead_hitters_obp(sals_with_batting_order)\n",
    "#trail_hitters_ops_dict = find_trail_hitters_ops(sals_with_batting_order)\n",
    "\n",
    "all_starters_projections_dict = generate_starting_pitcher_projections(starting_pitchers, pitcher_sals_with_vegas_lines, prior_year_ind_pitcher_dist, prior_year_league_innings_dist, current_year_ind_pitcher_dist, current_year_league_innings_dist, current_year_outs, weighted_league_innings_dist_mean, weighted_league_innings_dist_std, current_year_starts_vs_team, FIP_constant)\n",
    "\n",
    "projection_df = generate_projection_df_hitters(sals_with_batting_order)\n",
    "projection_df_p = generate_projection_df_pitchers(pitcher_sals_with_vegas_lines, all_starters_projections_dict, FIP_constant)\n",
    "\n",
    "p = projection_df_p[['PlayerID', 'TeamID', 'OperatorPlayerName', 'pIP', 'pK', 'pBB', 'pHR', 'pH', 'pHBP', 'pBF']]\n",
    "p = p[p.pIP > 1]\n",
    "p.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "p = p.reset_index(drop=True)\n",
    "\n",
    "b = projection_df[['PlayerID', 'TeamID', 'OperatorPlayerName', 'pPA', 'pR', 'pS', 'pD', 'pT', 'pHR', 'pRBI', 'pBB', 'pHP', 'pSO', 'Opponent_ID']]\n",
    "b.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "b = b.reset_index(drop=True)\n",
    "\n",
    "t = b.merge(p, left_on='Opponent_ID', right_on='TeamID')\n",
    "\n",
    "lg_a = game_logs[['PA', 'S', 'D', 'T', 'HR', 'BB', 'HP', 'SO']].reset_index(drop=True).mean().tolist()\n",
    "a_pa = lg_a[0]\n",
    "lg_p = [item / a_pa for item in lg_a]\n",
    "lg_a_h = lg_p[1] + lg_p[2] + lg_p[3] + lg_p[4]\n",
    "lg_p.append(lg_a_h)\n",
    "\n",
    "or_stats = ['HR', 'BB', 'HBP', 'SO', 'H']\n",
    "lg_a_or_dict = {}\n",
    "for i in range(len(or_stats)):\n",
    "    lg_a_or_dict[or_stats[i]] = lg_p[i + 4] / (1 - lg_p[i + 4])\n",
    "\n",
    "or_stats = ['HR', 'BB', 'HBP', 'SO', 'H']\n",
    "lg_a_or_dict = {}\n",
    "for i in range(len(or_stats)):\n",
    "    lg_a_or_dict[or_stats[i]] = lg_p[i + 4] / (1 - lg_p[i + 4])\n",
    "\n",
    "team_totals = {}\n",
    "OR_pitchers = {}\n",
    "pitcher_index = {}\n",
    "\n",
    "for r in t.index:\n",
    "    row = t.loc[r,:].tolist()\n",
    "    op = row[16]\n",
    "    pid = row[14]\n",
    "    team = row[15]\n",
    "    ip = row[17]\n",
    "    if op in pitcher_index: pass\n",
    "    else:\n",
    "        pitcher_index[op] = [pid, team, ip]\n",
    "\n",
    "# OR for pitchers\n",
    "for r in t.index:\n",
    "    row = t.loc[r, :].tolist()\n",
    "    n = row[16]\n",
    "    \n",
    "    bf = row[23]\n",
    "    \n",
    "    k_p = row[18] / bf\n",
    "    hr_p = row[20] / bf\n",
    "    bb_p = row[19] / bf\n",
    "    h_p = row[21] / bf\n",
    "    hbp_p = row[22] / bf\n",
    "    \n",
    "    p_or_k = k_p / (1 - k_p)\n",
    "    p_or_hr = hr_p / (1 - hr_p)\n",
    "    p_or_h = h_p / (1 - h_p)\n",
    "    p_or_bb = bb_p / (1 - bb_p)\n",
    "    p_or_hbp = hbp_p / (1 - hbp_p)    \n",
    "    \n",
    "    if n in OR_pitchers: pass\n",
    "    else:\n",
    "        OR_pitchers[n] = [p_or_k, p_or_hr, p_or_h, p_or_bb, p_or_hbp, bf]\n",
    "        \n",
    "for r in t.index:\n",
    "    row = t.loc[r, :].tolist()\n",
    "    batter_team = row[1]\n",
    "    if np.isnan(batter_team): continue\n",
    "    else:\n",
    "        # get total team projected outs\n",
    "        pa = row[3]\n",
    "        hits = row[5] + row[6] + row[7] + row[8]\n",
    "        outs = pa - hits - row[10] - row[11]\n",
    "\n",
    "        if np.isnan(outs) or np.isnan(pa): continue\n",
    "        elif batter_team in team_totals:\n",
    "            team_totals[batter_team][0] += pa\n",
    "            team_totals[batter_team][1] += outs\n",
    "        else: team_totals[batter_team] = [pa, outs]\n",
    "\n",
    "stats = ['SO', 'HR', 'H', 'BB', 'HBP']\n",
    "r_lst = []\n",
    "\n",
    "adj_p_dict = {}\n",
    "\n",
    "for r in t.index:\n",
    "    row = t.loc[r,:].tolist()\n",
    "    pa = row[3]\n",
    "    tm = row[1]\n",
    "    if np.isnan(tm) or np.isnan(row[4]): pass\n",
    "    else:\n",
    "        hits = row[5] + row[6] + row[7] + row[8]\n",
    "\n",
    "        # find odds ratio for K, HR, H, HBP, BB\n",
    "\n",
    "        k_p = row[12] / pa\n",
    "        hr_p = row[8] / pa\n",
    "        bb_p = row[10] / pa\n",
    "        h_p = hits / pa\n",
    "        hbp_p = row[11] / pa\n",
    "\n",
    "        b_or_k = k_p / (1 - k_p)\n",
    "        b_or_hr = hr_p / (1 - hr_p)\n",
    "        b_or_h = h_p / (1 - h_p)\n",
    "        b_or_bb = bb_p / (1 - bb_p)\n",
    "        b_or_hbp = hbp_p / (1 - hbp_p)\n",
    "\n",
    "        b_or = [b_or_k, b_or_hr, b_or_h, b_or_bb, b_or_hbp]\n",
    "\n",
    "        for i in range(5):\n",
    "            op = row[16]\n",
    "            if op in adj_p_dict: pass\n",
    "            else:\n",
    "                adj_p_dict[op] = [0, 0, 0, 0, 0]\n",
    "\n",
    "            adj_b_or = (b_or[i] * OR_pitchers[op][i]) / lg_a_or_dict[stats[i]]\n",
    "            adj_b_p = adj_b_or / (adj_b_or + 1)\n",
    "            ns = adj_b_p * pa\n",
    "\n",
    "            ps = round(ns / (team_totals[tm][0] / OR_pitchers[op][5]), 2)\n",
    "\n",
    "            pavspp = OR_pitchers[op][5] / (team_totals[tm][0] / (team_totals[tm][1] / 27))\n",
    "            ns_sp = ns * pavspp\n",
    "            ns_rp = (b_or[i] / (b_or[i] + 1)) * pa * (1 - pavspp)\n",
    "\n",
    "            adj_p_dict[op][i] += ps\n",
    "\n",
    "            ns_t = round(ns_rp + ns_sp, 2)\n",
    "\n",
    "            row.append(ns_t)\n",
    "\n",
    "        r_lst.append(row)   \n",
    "        \n",
    "g = pd.DataFrame(r_lst)\n",
    "g.columns = t.columns.tolist() + ['nK', 'nHR', 'nH', 'nBB', 'nHBP']\n",
    "g = g[['PlayerID_x', 'TeamID_x', 'OperatorPlayerName_x', 'nK', 'nHR', 'nH', 'nBB', 'nHBP']]\n",
    "g = g.rename(columns={\"PlayerID_x\": \"PlayerID\", \"TeamID_x\": \"TeamID\", 'OperatorPlayerName_x': 'Name', 'nK': 'K', 'nHR': 'HR', 'nH': 'H', 'nBB': 'BB', 'nHBP': 'HBP'})\n",
    "\n",
    "b_info = projection_df[['PlayerID', 'SlateID', 'Operator', 'OperatorPlayerID', 'OperatorSalary', 'OperatorGameType', 'OperatorRosterSlots', 'pPA', 'pR', 'pS', 'pD', 'pT', 'pRBI', 'pSB']]\n",
    "b_info = b_info.rename(columns={\"pPA\": \"PA\", \"pR\": \"R\", 'pRBI': 'RBI', 'pSB': 'SB'})\n",
    "b_info = b_info[b_info['OperatorGameType'] == 'Classic'].reset_index(drop=True)\n",
    "\n",
    "batters_final_df = g.merge(b_info, how='left', on='PlayerID')\n",
    "\n",
    "batters_final_df['1B'] = batters_final_df.apply(lambda row: (row['pS'] / (row['pS'] + row['pD'] + row['pT'])) * (row['H'] - row['HR']) , axis=1)\n",
    "batters_final_df['2B'] = batters_final_df.apply(lambda row: (row['pD'] / (row['pS'] + row['pD'] + row['pT'])) * (row['H'] - row['HR']) , axis=1)\n",
    "batters_final_df['3B'] = batters_final_df.apply(lambda row: (row['pT'] / (row['pS'] + row['pD'] + row['pT'])) * (row['H'] - row['HR']) , axis=1)\n",
    "batters_final_df['DraftKingsPoints'] = batters_final_df.apply(lambda row: round((3 * row['1B']) + (5 * row['2B']) + (8 * row['3B']) + (10 * row['HR']) + (2 * row['RBI']) + (2 * row['R']) + (2 * row['BB']) + (2 * row['HBP']) + (5 * row['SB']), 2), axis=1)\n",
    "batters_final_df['FanDuelPoints'] = batters_final_df.apply(lambda row: round((3 * row['1B']) + (6 * row['2B']) + (9 * row['3B']) + (12 * row['HR']) + (3.5 * row['RBI']) + (3.2 * row['R']) + (3 * row['BB']) + (3 * row['HBP']) + (6 * row['SB']), 2), axis=1)\n",
    "\n",
    "bfd = batters_final_df[['PlayerID', 'TeamID', 'SlateID', 'Operator', 'OperatorPlayerID', 'OperatorSalary', 'OperatorGameType', 'Name', 'OperatorRosterSlots', 'PA', 'H', 'R', '1B', '2B', '3B', 'HR', 'RBI', 'K', 'BB', 'HBP', 'SB', 'DraftKingsPoints', 'FanDuelPoints']]\n",
    "\n",
    "for key in pitcher_index:\n",
    "    adj_p_dict[key] += pitcher_index[key]\n",
    "\n",
    "v = pd.DataFrame.from_dict(adj_p_dict, orient='index')\n",
    "v = v.reset_index()\n",
    "v.columns = ['Name', 'K', 'HR', 'H', 'BB', 'HBP', 'PlayerID', 'TeamID', 'IP']\n",
    "\n",
    "p_info = projection_df_p[['PlayerID', 'SlateID', 'Operator', 'OperatorPlayerID', 'OperatorSalary', 'OperatorGameType', 'OperatorRosterSlots', 'pW', 'pQS']]\n",
    "p_info = p_info[p_info['OperatorGameType'] == 'Classic'].reset_index(drop=True)\n",
    "pitchers_final_df = v.merge(p_info, how='left', on='PlayerID')\n",
    "\n",
    "pitchers_final_df['ER'] = pitchers_final_df.apply(lambda row: round(((((13 * row['HR']) + (3 * (row['BB'] + row['HBP'])) - (2 * row['K'])) / row['IP']) + FIP_constant) * (row['IP'] / 9), 2), axis=1)\n",
    "pitchers_final_df['TBF'] = pitchers_final_df.apply(lambda row: round(3 * row['IP'] + row['BB'] + row['H'] + row['HBP'], 2), axis=1)\n",
    "pitchers_final_df['DraftKingsPoints'] = pitchers_final_df.apply(lambda row: round(row['IP'] * 2.25 + row['K'] * 2 + row['pW'] * 4 + row['ER'] * -2 + row['H'] * -0.6 + row['BB'] * -0.6 + row['HBP'] * -0.6, 2), axis=1)\n",
    "pitchers_final_df['FanDuelPoints'] = pitchers_final_df.apply(lambda row: round(row['pW'] * 6 + row['pQS'] * 4 + row['ER'] * -3 + row['K'] * 3 + row['IP'] * 3, 2), axis=1)\n",
    "\n",
    "pfd = pitchers_final_df.rename(columns={\"pW\": \"W\", \"pQS\": \"QS\"})\n",
    "pfd = pfd[['PlayerID', 'TeamID', 'SlateID', 'Operator', 'OperatorPlayerID', 'OperatorSalary', 'OperatorGameType', 'Name', 'OperatorRosterSlots', 'IP', 'TBF', 'W', 'QS', 'H', 'ER', 'HR', 'K', 'BB', 'HBP', 'DraftKingsPoints', 'FanDuelPoints']]\n",
    "\n",
    "pfd['DK$'] = pfd.apply(lambda r: round(r['DraftKingsPoints'] / (r['OperatorSalary'] / 1000), 2) , axis=1)\n",
    "pfd['FD$'] = pfd.apply(lambda r: round(r['FanDuelPoints'] / (r['OperatorSalary'] / 1000), 2) , axis=1)\n",
    "\n",
    "bfd['TB'] = bfd.apply(lambda r: round(r['1B'] + 2 * r['2B'] + 3 * r['3B'] + 4 * r['HR'], 2), axis=1)\n",
    "bfd['DK$'] = bfd.apply(lambda r: round(r['DraftKingsPoints'] / (r['OperatorSalary'] / 1000), 2) , axis=1)\n",
    "bfd['FD$'] = bfd.apply(lambda r: round(r['FanDuelPoints'] / (r['OperatorSalary'] / 1000), 2) , axis=1)\n",
    "\n",
    "pid_map = pd.read_csv('player_id_map.csv')\n",
    "pid_map = pid_map[['mlbname', 'mlbid']].dropna()\n",
    "pid_map2 = pd.read_csv('names_id_df.csv')\n",
    "comb_ids = pd.concat([pid_map, pid_map2]).reset_index(drop=True)\n",
    "\n",
    "bfd['Name_u'] = bfd.apply(lambda r: unidecode.unidecode(r['Name']), axis=1)\n",
    "pfd['Name_u'] = pfd.apply(lambda r: unidecode.unidecode(r['Name']), axis=1)\n",
    "\n",
    "pfd = pfd.merge(comb_ids, how='left', left_on='Name_u', right_on='mlbname')\n",
    "bfd = bfd.merge(comb_ids, how='left', left_on='Name_u', right_on='mlbname')\n",
    "\n",
    "\n",
    "names_to_lookup = []\n",
    "\n",
    "for i in range(len(pfd.index)):\n",
    "    r = pfd.loc[i, ['Name', 'mlbid']].tolist()\n",
    "    name = unidecode.unidecode(r[0])\n",
    "    if np.isnan(r[1]) and name not in names_to_lookup: names_to_lookup.append(name) \n",
    "    else: continue\n",
    "        \n",
    "for i in range(len(bfd.index)):\n",
    "    r = bfd.loc[i, ['Name', 'mlbid']].tolist()\n",
    "    name = unidecode.unidecode(r[0])\n",
    "    if np.isnan(r[1]) and name not in names_to_lookup: names_to_lookup.append(name) \n",
    "    else: continue\n",
    "        \n",
    "additional_names = []\n",
    "\n",
    "for n in names_to_lookup:\n",
    "    ns = n.split(' ')\n",
    "    try:\n",
    "        data = playerid_lookup(ns[1], ns[0])\n",
    "        pid = data['key_mlbam'][0]\n",
    "    except: continue\n",
    "    additional_names.append([n, pid])\n",
    "    \n",
    "additional_names_df = pd.DataFrame(additional_names, columns = ['mlbname', 'mlbid'])\n",
    "comb_df = pd.concat([pid_map2, additional_names_df]).reset_index(drop=True)\n",
    "comb_df.to_csv('names_id_df.csv', index=False)\n",
    "\n",
    "pfd = pfd.merge(additional_names_df, how='left', left_on='Name_u', right_on='mlbname')\n",
    "bfd = bfd.merge(additional_names_df, how='left', left_on='Name_u', right_on='mlbname')\n",
    "\n",
    "bfd['pid'] = bfd['mlbid_x'].combine_first(bfd['mlbid_y'])\n",
    "pfd['pid'] = pfd['mlbid_x'].combine_first(pfd['mlbid_y'])\n",
    "\n",
    "bfd = bfd.drop(['Name_u', 'mlbname_x', 'mlbid_x', 'mlbname_y', 'mlbid_y'], axis=1)\n",
    "bfd = bfd.rename(columns={\"PlayerID\": \"SportsDataIO_ID\", \"pid\": \"PlayerID\"})\n",
    "\n",
    "first_column = bfd.pop('PlayerID')\n",
    "bfd.insert(0, 'PlayerID', first_column)\n",
    "\n",
    "pfd = pfd.drop(['Name_u', 'mlbname_x', 'mlbid_x', 'mlbname_y', 'mlbid_y'], axis=1)\n",
    "pfd = pfd.rename(columns={\"PlayerID\": \"SportsDataIO_ID\", \"pid\": \"PlayerID\"})\n",
    "\n",
    "first_column = pfd.pop('PlayerID')\n",
    "pfd.insert(0, 'PlayerID', first_column)\n",
    "\n",
    "dk_sal = {}\n",
    "fd_sal = {}\n",
    "\n",
    "for i in range(len(pfd.index)):\n",
    "    r = pfd.loc[i, :].tolist()\n",
    "    \n",
    "    op = r[4]\n",
    "    op_sal = r[6]\n",
    "    p = r[8]\n",
    "    \n",
    "    if op == 'DraftKings':\n",
    "        if p in dk_sal: pass\n",
    "        else: dk_sal[p] = op_sal\n",
    "    elif op == 'FanDuel':\n",
    "        if p in fd_sal: pass\n",
    "        else: fd_sal[p] = op_sal\n",
    "    else: continue\n",
    "        \n",
    "for i in range(len(bfd.index)):\n",
    "    r = bfd.loc[i, :].tolist()\n",
    "    \n",
    "    op = r[4]\n",
    "    op_sal = r[6]\n",
    "    p = r[8]\n",
    "    \n",
    "    if op == 'DraftKings':\n",
    "        if p in dk_sal: pass\n",
    "        else: dk_sal[p] = op_sal\n",
    "    elif op == 'FanDuel':\n",
    "        if p in fd_sal: pass\n",
    "        else: fd_sal[p] = op_sal\n",
    "    else: continue\n",
    "        \n",
    "bfd['DraftKingsSalary'] = bfd.apply(lambda r: dk_sal[r['Name']] if r['Name'] in dk_sal else 0, axis=1)\n",
    "bfd['FanDuelSalary'] = bfd.apply(lambda r: fd_sal[r['Name']] if r['Name'] in fd_sal else 0, axis=1)\n",
    "\n",
    "pfd['DraftKingsSalary'] = pfd.apply(lambda r: dk_sal[r['Name']] if r['Name'] in dk_sal else 0, axis=1)\n",
    "pfd['FanDuelSalary'] = pfd.apply(lambda r: fd_sal[r['Name']] if r['Name'] in fd_sal else 0, axis=1)\n",
    "\n",
    "bfd = bfd.drop_duplicates(subset=[\"Name\"], keep='first')\n",
    "bfd = bfd.dropna(subset=['PlayerID']).reset_index(drop=True)\n",
    "\n",
    "pfd = pfd.drop_duplicates(subset=[\"Name\"], keep='first')\n",
    "pfd = pfd.dropna(subset=['PlayerID']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "bfd = bfd.drop(['SlateID', 'Operator', 'OperatorPlayerID', 'OperatorSalary', 'OperatorGameType'], axis=1)\n",
    "pfd = pfd.drop(['SlateID', 'Operator', 'OperatorPlayerID', 'OperatorSalary', 'OperatorGameType'], axis=1)\n",
    "\n",
    "p_out = pfd.to_json(orient='index')\n",
    "b_out = bfd.to_json(orient='index')\n",
    "\n",
    "p_object = json.loads(p_out)\n",
    "b_object = json.loads(b_out)\n",
    "\n",
    "pfd.to_csv('pitchers_test.csv', index=False)\n",
    "bfd.to_csv('batters_test.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13377f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
